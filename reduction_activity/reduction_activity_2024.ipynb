{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reduction\n",
    "In this activity, you will be reducing the data we took last week. In this notebook, you will learn how to go from raw data taken on a telescope and create science ready images! \n",
    "\n",
    "By the end of this activity, you will be ready to create a pretty 3-color image like this one:\n",
    "\n",
    "![image](rsw-0023-RGB.jpg)\n",
    "\n",
    "Credit: Richard S. Wright Jr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Required imports\n",
    "In order to reduce our data, we will need to import a few handy packages with the following call:\n",
    "- import reduction (reduction packages for Nickel 1-m)\n",
    "- from astropy.io import fits (to open on image files)\n",
    "- import matplotlib.pyplot as plt (to show our image files)\n",
    "- import numpy as np (certain math functions)\n",
    "- import shutil (helpful for moving files around)\n",
    "- glob (good for grabbing lists of files in directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# required imports\n",
    "import reduction\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overscan subtraction\n",
    "An overscan region of the CCD chip that is not exposed to light. The overscan region keeps track of the *bias* level throughout the night; as a reminder, the *bias* is a zero second exposure which tells us how \"bright\" each pixel is without any light hitting the camera. For this reason, the overscan region it is a useful way to remove small variations in the bias level throughout the night. We must first remove these columns and apply an overscan subtraction before we begin on data reduction.\n",
    "\n",
    "### We'll first look at our raw images to see the overscan region. Pick any file of interest and plot the image below. There are two overscan regions: one, near a bright column of *bad pixels* (we'll deal with these later) and a faint column to the right of the image. You may have to play around with the scaling of your image to see these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yourfile = './data-2024-07-02-nickel/raw/YOURFILEHERE' # put in your file here\n",
    "data = fits.getdata(yourfile) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data, origin='lower', vmin=0, vmax=5000) # change vmax to change the scaling\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To perform the overscan subtraction, we will use the reduction package and call the function overscan_subtraction(*files*) which takes a list of raw files as an argument. In the following cell, we will create a list of all the data files and perform the overscan subtraction. \n",
    "\n",
    "Files that have been overscan subtracted will have an _os subscript. As a note, this may take a minute to run so as the cell is running, check out your raw directory. Do you see new files being created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_dir = './data-2024-07-02-nickel/raw/'\n",
    "files = source_dir + '*.fits'\n",
    "\n",
    "reduction.overscan_subtraction(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the overscan subtracted raw image from before. Are the overscan regions still there?\n",
    "\n",
    "As a note, this image should end with _os.fits, meaning an overscan subtracted file. Both overscan columns should be gone (but the bright columns of bad pixels will remain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yourfile = './data-2024-07-02-nickel/raw/YOURFILEHERE' # put in your file here\n",
    "data = fits.getdata(yourfile) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data, origin='lower', vmin=0, vmax=9000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Move files to correct directories\n",
    "Having our overscan subtracted data, we can move our files to the correct directories for data reduction. In the data-2024-07-02-nickel directory, you should see a few different folders: \n",
    "- calibration, containing a folder named bias, halpha_flat, r_flat, and v_flat; this folder will store our calibration files.\n",
    "- raw; this folder stores our raw files + overscan subtracted\n",
    "- science\n",
    "\n",
    "In this step, we will use the log and move each file into the correct folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_frames = range()\n",
    "v_flat_frames = range()\n",
    "r_flat_frames = range()\n",
    "b_flat_frames = range()\n",
    "halpha_flat_frames = range()\n",
    "science_frames = range()\n",
    "\n",
    "v_flat_files = ['{0}d{1}_os.fits'.format(source_dir, num) for num in v_flat_frames]\n",
    "b_flat_files = ['{0}d{1}_os.fits'.format(source_dir, num) for num in b_flat_frames]\n",
    "r_flat_files = ['{0}d{1}_os.fits'.format(source_dir, num) for num in r_flat_frames]\n",
    "halpha_flat_files = ['{0}d{1}_os.fits'.format(source_dir, num) for num in halpha_flat_frames]\n",
    "bias_files = ['{0}d{1}_os.fits'.format(source_dir, num) for num in bias_frames]\n",
    "science_files = ['{0}d{1}_os.fits'.format(source_dir, num) for num in science_frames]\n",
    "\n",
    "# copy over each file into the correct directory\n",
    "path = './data-2024-07-02-nickel/'\n",
    "for file in v_flat_files:\n",
    "    shutil.copy2(file, path+'calibration/v_flat')\n",
    "\n",
    "for file in b_flat_files:\n",
    "    shutil.copy2(file, path+'calibration/b_flat')\n",
    "\n",
    "for file in halpha_flat_files:\n",
    "    shutil.copy2(file, path+'calibration/halpha_flat')\n",
    "\n",
    "for file in r_flat_files:\n",
    "    shutil.copy2(file, path+'calibration/r_flat')\n",
    "\n",
    "for file in bias_files:\n",
    "    shutil.copy2(file, path+'calibration/bias')\n",
    "\n",
    "for file in science_files:\n",
    "    shutil.copy2(file, path+'science')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Master bias\n",
    "As we said before, the *bias* is a zero second exposure that characterizes the behavoir of our detector when it's not exposed to light; each pixel will have a slightly different bias value. Although the bias level tends to be small, we must remove these extra pixel counts so they don't contribute to our image. To do this, we median combine our bias frames to create a *master bias*. We will then subtract this bias from all images taken with a non-zero exposure, or, our science images and our flats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bias_path = path+'calibration/bias/'\n",
    "bias_files = glob.glob(bias_path+'*_os.fits')\n",
    "data_stack = []\n",
    "\n",
    "# create a list of bias frames \n",
    "for frame in bias_files:\n",
    "    data_stack.append(fits.getdata(frame))\n",
    "\n",
    "# Median combine the bias files to create the master bias frame\n",
    "medianBias = np.median(data_stack, axis=0)\n",
    "\n",
    "# Write out the master bias file (bias.fits) with updated FITS header information\n",
    "header = fits.getheader(bias_files[0])\n",
    "header['HISTORY'] = 'Median combined'\n",
    "fits.writeto(bias_path+'bias.fits',medianBias,header,overwrite=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's open our master bias, which we bias.fits and svaed in the calibration/bias folder. What is the average count level in this bias frame? Is this a small or large value compared to the total number of counts that a single pixel can have (around ~65,000)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yourbias = path+'calibration/bias/YOURBIAS' \n",
    "data = fits.getdata(yourbias) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data, origin='lower', vmin=0, vmax=100)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixel]')\n",
    "plt.ylabel('Y [pixel]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bias subtract all frames\n",
    "Because the bias is in all frames, we must remove it from both our flats frames and our science frames before we can do anything else. I will show an example of how to do this for some of the flat frames (just the b flats), your job will be to do it for the rest of the files. As a note, the bias subtracted frames will be denoted by a _bs.fits to highlight that this frame has had the bias removed already. When you run your cells, check that your bias subtracted files are created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias subtract flat frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bias subtracting the b_flat frames\n",
    "# Make list of input bias files\n",
    "datafilesin = glob.glob(path+'calibration/b_flat/*_os.fits')\n",
    "\n",
    "# _bs stands for bias subtracted in the output file names\n",
    "datafilesout = [i[:-5]+ '_bs.fits' for i in datafilesin]\n",
    "\n",
    "n = len(datafilesin)\n",
    "\n",
    "# for each flat in the list b_flat, will bias subtract it\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(datafilesin[i],header=True)\n",
    "    dataout = data - medianBias\n",
    "    header['HISTORY'] = 'Bias subtracted'\n",
    "    fits.writeto(datafilesout[i],dataout,header,overwrite=True)\n",
    "\n",
    "########\n",
    "\n",
    "# Bias subtracting the r_flat frames\n",
    "# Make list of input bias files\n",
    "datafilesin = glob.glob(path+'calibration/YOURFLATFOLDERHERE/*_os.fits')\n",
    "\n",
    "# _bs stands for bias subtracted in the output file names\n",
    "datafilesout = [i[:-5]+ '_bs.fits' for i in datafilesin]\n",
    "\n",
    "n = len(datafilesin)\n",
    "\n",
    "# for each flat in the list r_flat, will bias subtract it\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(datafilesin[i],header=True)\n",
    "    dataout = data - medianBias\n",
    "    header['HISTORY'] = 'Bias subtracted'\n",
    "    fits.writeto(datafilesout[i],dataout,header,overwrite=True)\n",
    "\n",
    "########\n",
    "\n",
    "# Bias subtracting the halpha_flat\n",
    "# Make list of input bias files\n",
    "datafilesin = glob.glob(path+'calibration/YOURFLATFOLDERHERE/*_os.fits')\n",
    "\n",
    "# _bs stands for bias subtracted in the output file names\n",
    "datafilesout = [i[:-5]+ '_bs.fits' for i in datafilesin]\n",
    "\n",
    "n = len(datafilesin)\n",
    "\n",
    "# for each flat in the list halpha_flat, will bias subtract it\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(datafilesin[i],header=True)\n",
    "    dataout = data - medianBias\n",
    "    header['HISTORY'] = 'Bias subtracted'\n",
    "    fits.writeto(datafilesout[i],dataout,header,overwrite=True)\n",
    "\n",
    "######## \n",
    "\n",
    "# Bias subtracting the v_flat\n",
    "# Make list of input bias files\n",
    "datafilesin = glob.glob(path+'calibration/YOURFLATFOLDERHERE/*_os.fits')\n",
    "\n",
    "# _bs stands for bias subtracted in the output file names\n",
    "datafilesout = [i[:-5]+ '_bs.fits' for i in datafilesin]\n",
    "\n",
    "n = len(datafilesin)\n",
    "\n",
    "# for each flat in the list halpha_flat, will bias subtract it\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(datafilesin[i],header=True)\n",
    "    dataout = data - medianBias\n",
    "    header['HISTORY'] = 'Bias subtracted'\n",
    "    fits.writeto(datafilesout[i],dataout,header,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias subtract science frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bias subtracting the science frames\n",
    "\n",
    "# Make list of input bias files\n",
    "datafilesin = glob.glob(path+'YOURSCIENCEDIRECTORYHERE/*_os.fits')\n",
    "\n",
    "# _bs stands for bias subtracted in the output file names\n",
    "datafilesout = [i[:-5]+ '_bs.fits' for i in datafilesin]\n",
    "\n",
    "n = len(datafilesin)\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(datafilesin[i],header=True)\n",
    "    dataout = data - medianBias\n",
    "    header['HISTORY'] = 'Bias subtracted'\n",
    "    fits.writeto(datafilesout[i],dataout,header,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create normalized flat-field for each filter\n",
    "In an ideal system, each pixel would respond the same if the CCD is illuminated uniformly. In reality, though, each pixel has a different response and sensitivity to light, and this response changes filter to filter. A flat-field removes this behavior and divides out the uneven response.\n",
    "\n",
    "### To see the importance of flat-fielding, let's first plot a bias subtracted science frame. Choose any and plot it below. Do you see anything weird about this frame (spots, donuts, dark spots)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yourfile = path+'science/YOURFILEHERE' # put in your file here\n",
    "data = fits.getdata(yourfile) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data, origin='lower', vmin=0, vmax=1000)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's create our flats for each filter \n",
    "Here, you'll create a *normalized* (i.e. all the values are between 0 and 1) flat-field for each filter: B, R, V, and H-alpha. I'll do the first for you (B) and you'll complete the rest. These files will be saved in the /calibration/flats folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the master b_flat (bflat.fits)\n",
    "\n",
    "b_flist = glob.glob(path+'calibration/b_flat/*_bs.fits')\n",
    "bflat_stack = []\n",
    "\n",
    "# Read in each file and normalize by the median\n",
    "for file in b_flist:\n",
    "    data, header = fits.getdata(file,header=True) # read in the flat file data\n",
    "    data = data / np.median(data) \n",
    "    bflat_stack.append(data)\n",
    "\n",
    "# Median combine the flat fields, then normalize by the mean    \n",
    "bflat = np.median(bflat_stack, axis=0)\n",
    "m = np.mean(bflat)\n",
    "bflat = bflat/m\n",
    "header['HISTORY'] = 'Combined and normalized flat field'\n",
    "fits.writeto(path+'calibration/flats/' + 'bflat.fits',bflat,header,overwrite=True)\n",
    "\n",
    "###### \n",
    "\n",
    "# create the master r_flat (rflat.fits)\n",
    "\n",
    "r_flist = glob.glob(path+'calibration/YOURFILTERHERE/*_bs.fits')\n",
    "rflat_stack = []\n",
    "\n",
    "# Read in each file and normalize by the median\n",
    "for file in r_flist:\n",
    "    data, header = fits.getdata(file,header=True) # read in the flat file data\n",
    "    data = data / np.median(data) \n",
    "    rflat_stack.append(data)\n",
    "\n",
    "# Median combine the flat fields, then normalize by the mean    \n",
    "rflat = np.median(rflat_stack, axis=0)\n",
    "m = np.mean(rflat)\n",
    "rflat = rflat/m\n",
    "header['HISTORY'] = 'Combined and normalized flat field'\n",
    "fits.writeto(path+'calibration/flats/' + 'YOURFLATNAMEHERE.fits',rflat,header,overwrite=True)\n",
    "\n",
    "###### \n",
    "\n",
    "# create the master halpha_flat (halphaflat.fits)\n",
    "\n",
    "halpha_flist = glob.glob(path+'calibration/YOURFILTERHERE/*_bs.fits')\n",
    "halphaflat_stack = []\n",
    "\n",
    "# Read in each file and normalize by the median\n",
    "for file in halpha_flist:\n",
    "    data, header = fits.getdata(file,header=True) # read in the flat file data\n",
    "    data = data / np.median(data) \n",
    "    halphaflat_stack.append(data)\n",
    "\n",
    "# Median combine the flat fields, then normalize by the mean    \n",
    "halphaflat = np.median(halphaflat_stack, axis=0)\n",
    "m = np.mean(halphaflat)\n",
    "halphaflat = halphaflat/m\n",
    "header['HISTORY'] = 'Combined and normalized flat field'\n",
    "fits.writeto(path+'calibration/flats/' + 'YOURFLATNAMEHERE.fits',halphaflat,header,overwrite=True)\n",
    "\n",
    "###### \n",
    "\n",
    "# create the master v_flat (halphaflat.fits)\n",
    "\n",
    "v_flist = glob.glob(path+'calibration/YOURFILTERHERE/*_bs.fits')\n",
    "vflat_stack = []\n",
    "\n",
    "# Read in each file and normalize by the median\n",
    "for file in v_flist:\n",
    "    data, header = fits.getdata(file,header=True) # read in the flat file data\n",
    "    data = data / np.median(data) \n",
    "    vflat_stack.append(data)\n",
    "\n",
    "# Median combine the flat fields, then normalize by the mean    \n",
    "vflat = np.median(vflat_stack, axis=0)\n",
    "m = np.mean(vflat)\n",
    "vflat = vflat/m\n",
    "header['HISTORY'] = 'Combined and normalized flat field'\n",
    "fits.writeto(path+'calibration/flats/' + 'YOURFLATNAMEHERE.fits',vflat,header,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at one of the flat-fields we created. Do you see the pixel-by-pixel response change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yourflat = path+'calibration/flats/YOURFILEHERE' # put in your file here\n",
    "data = fits.getdata(yourflat) # here, we read in the fits file using the astropy package\n",
    "plt.imshow(data, origin='lower')\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Flat-field science frames\n",
    "Now that we have our flat frames we can flat-field our science frames. We'll make a three color image of NGC5907 (galaxy) for this activity.\n",
    "\n",
    "First, let's plot the science frames, before flat-fielding for our object. As a note, not all objects will have all 4 filters. \n",
    "### Looking at the log, figure out what frame corresponds to each filter four your object and plot it. Play around with the scaling if you find it hard to see features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B filter\n",
    "yourfilt1 = path+'science/YOURFILENUMBERHERE' # put in your file here\n",
    "data1 = fits.getdata(yourfilt1) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data1, origin='lower', vmin=0, vmax=100)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()\n",
    "\n",
    "# V filter\n",
    "yourfilt2 = path+'science/YOURFILENUMBERHERE' # put in your file here\n",
    "data2 = fits.getdata(yourfilt2) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data2, origin='lower', vmin=0, vmax=1000)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()\n",
    "\n",
    "# R filter\n",
    "yourfilt3 = path+'science/YOURFILENUMBERHERE' # put in your file here\n",
    "data3 = fits.getdata(yourfilt3) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data3, origin='lower', vmin=0, vmax=1000)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we can flat-field each of our frames using the flats we made above. \n",
    "The flat-fielded frame will be named as _ff to mark that it's been flat-fielded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B filter\n",
    "\n",
    "# _ff stand for flat fielded for the output file name\n",
    "bdataout = [i[:-5]+ '_ff.fits' for i in [path+'science/YOURBFILEHERE']]\n",
    "b_flist = [path+'science/d26_os_bs.fits']\n",
    "\n",
    "# For each file in list, divide by the normalize flat field frame for that filter\n",
    "n=len(b_flist)\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(b_flist[i],header=True)\n",
    "    dataout = data / bflat\n",
    "    header['HISTORY'] = 'Flat Fielded'\n",
    "    fits.writeto(bdataout[i],dataout,header,overwrite=True)\n",
    "\n",
    "# V filter\n",
    "\n",
    "# _ff stand for flat fielded for the output file name\n",
    "vdataout = [i[:-5]+ '_ff.fits' for i in [path+'science/YOURVFILEHERE']]\n",
    "v_flist = [path+'science/d27_os_bs.fits']\n",
    "\n",
    "# For each file in list, divide by the normalize flat field frame for that filter\n",
    "n=len(v_flist)\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(v_flist[i],header=True)\n",
    "    dataout = data / vflat\n",
    "    header['HISTORY'] = 'Flat Fielded'\n",
    "    fits.writeto(vdataout[i],dataout,header,overwrite=True)\n",
    "\n",
    "# R filter\n",
    "\n",
    "# _ff stand for flat fielded for the output file name\n",
    "rdataout = [i[:-5]+ '_ff.fits' for i in [path+'science/YOURRFILEHERE']]\n",
    "r_flist = [path+'science/d28_os_bs.fits']\n",
    "\n",
    "# For each file in list, divide by the normalize flat field frame for that filter\n",
    "n=len(r_flist)\n",
    "for i in range(0,n):\n",
    "    data,header = fits.getdata(r_flist[i],header=True)\n",
    "    dataout = data / rflat\n",
    "    header['HISTORY'] = 'Flat Fielded'\n",
    "    fits.writeto(rdataout[i],dataout,header,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at our science images again now that they're flat-fielded. What do you notice about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B filter\n",
    "yourfilt1 = path+'science/YOURFILEHERE' # put in your file here\n",
    "data1 = fits.getdata(yourfilt1) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data1, origin='lower', vmin=0, vmax=500)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()\n",
    "\n",
    "# V filter\n",
    "yourfilt2 = path+'science/YOURFILEHERE' # put in your file here\n",
    "data2 = fits.getdata(yourfilt2) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data2, origin='lower', vmin=0, vmax=1000)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()\n",
    "\n",
    "# R filter\n",
    "yourfilt3 = path+'science/YOURFILEHERE' # put in your file here\n",
    "data3 = fits.getdata(yourfilt3) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data3, origin='lower', vmin=0, vmax=1000)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bad pixel removal\n",
    "The time has finally come ... we can remove that ugly column going through our data! We will use a bad pixel removal routine in the reduction package, called remove_bad_pixels(*files_in*, *files_out*), which takes a list of files in and files out. Essentially, this function looks for known bad columns in the Nickel 1-m CCD.\n",
    "\n",
    "### Let's gather our flat-fielded science files and perform the bad-pixel subtraction \n",
    "Anything that has been bad-pixel subtracted will be marked with a _bp, meaning bad pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_in = glob.glob(path+'science/*_ff.fits')\n",
    "files_out = [file[:-5]+'_bp.fits' for file in files_in]\n",
    "\n",
    "reduction.remove_bad_pixels(files_in, files_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, plot your bad-pixel removed images. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B filter\n",
    "yourfilt1 = path+'science/YOURFILEHERE' # put in your file here\n",
    "data1 = fits.getdata(yourfilt1) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data1, origin='lower', vmin=0, vmax=100)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()\n",
    "\n",
    "# V filter\n",
    "yourfilt2 = path+'science/YOURFILEHERE' # put in your file here\n",
    "data2 = fits.getdata(yourfilt2) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data2, origin='lower', vmin=0, vmax=1000)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()\n",
    "\n",
    "# R filter\n",
    "yourfilt3 = path+'science/YOURFILEHERE' # put in your file here\n",
    "data3 = fits.getdata(yourfilt3) # here, we read in the fits file using the astropy package\n",
    "\n",
    "plt.imshow(data3, origin='lower', vmin=0, vmax=1000)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('X [pixels]')\n",
    "plt.ylabel('Y [pixels]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Creating an RGB image\n",
    "You now are ready to create an RGB image using the data you just cleaned!\n",
    "We will use a software called JS9 to create our images at this link: https://js9.si.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, load in all your cleaned frames. Go to the File tab and click 'open local'. Find each of your cleaned frames and upload them. They should begin to appear under the Images list.\n",
    "\n",
    "![image](./js9/step2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, select the color tab. Go down and click the 'rgb mode' option as shown below\n",
    "\n",
    "![image](./js9/step1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you can select which files correspond to Red, Green, and Blue. Click on an image using the File tab then select the Color tab. There, color options should appear. Choose Red, Blue, or Green depending on the filter of the image.\n",
    "![image](./js9/step3.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40b05493ddcf8e9507683538249caa61aa01626b793e566d994882f595f5286b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
